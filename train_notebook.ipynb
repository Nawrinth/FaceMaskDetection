{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB88Aqsge8nz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D , Dense , Dropout , Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p1arvjNfcw5",
        "outputId": "5eb32cb3-1b19-4b4c-af19-c6bfc4befff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/omkargurav/face-mask-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 163M/163M [00:08<00:00, 20.6MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/omkargurav/face-mask-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "source = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDRUJFeD0L4I",
        "outputId": "fb2bf9c9-041f-4408-c671-ff391d4adecd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['with_mask', 'without_mask']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source+=\"/data\"\n",
        "import os\n",
        "os.listdir(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHRNx1M_0Nx9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(source , destination , train_size , val_size):\n",
        "  classes = os.listdir(source)\n",
        "\n",
        "  for cls in classes:\n",
        "    path = os.path.join(source , cls)\n",
        "    print(f\"Class {cls} path: {path}\")\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_end = int(len(files)*train_size)\n",
        "    val_end = int(len(files)*(train_size+val_size))\n",
        "\n",
        "    train_files = files[:train_end]\n",
        "    val_files = files[train_end:val_end]\n",
        "    test_files = files[val_end:]\n",
        "\n",
        "    for split in ['train','val' , 'test']:\n",
        "      os.makedirs(os.path.join(destination , split , cls) , exist_ok=True)\n",
        "\n",
        "    def copy_files(img_list , split):\n",
        "      for img in img_list:\n",
        "        src = os.path.join(path , img)\n",
        "        dst = os.path.join(destination , split , cls , img)\n",
        "        shutil.copy(src , dst)\n",
        "\n",
        "    copy_files(train_files , 'train')\n",
        "    copy_files(val_files , 'val')\n",
        "    copy_files(test_files , 'test')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4BOGWlq-Ywo",
        "outputId": "c6e0b1a5-1d10-4145-9ebe-14b92cce6ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class with_mask path: /root/.cache/kagglehub/datasets/omkargurav/face-mask-dataset/versions/1/data/with_mask\n",
            "Class without_mask path: /root/.cache/kagglehub/datasets/omkargurav/face-mask-dataset/versions/1/data/without_mask\n"
          ]
        }
      ],
      "source": [
        "split_data(source,\"output\",0.7,0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib4oNAYw-uH0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "finalpath = \"output\"\n",
        "train = os.path.join(finalpath , \"train\")\n",
        "val = os.path.join(finalpath , \"val\")\n",
        "test = os.path.join(finalpath , \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah5DHz-NEZ4Y"
      },
      "outputs": [],
      "source": [
        "class FaceMaskDetector:\n",
        "  def __init__(self , image_size=(224,224) , freeze_layers=True):\n",
        "    self.image_size = image_size\n",
        "    self.freeze_layers = freeze_layers\n",
        "    self.model = None\n",
        "\n",
        "\n",
        "  def preprocessData(self , base_path):\n",
        "    train = os.path.join(base_path , \"train\")\n",
        "    val = os.path.join(base_path , \"val\")\n",
        "    test = os.path.join(base_path , \"test\")\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = preprocess_input,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = preprocess_input\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = preprocess_input\n",
        "    )\n",
        "\n",
        "    train_ds = train_datagen.flow_from_directory(\n",
        "        train,\n",
        "        target_size=self.image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_ds = val_datagen.flow_from_directory(\n",
        "        val,\n",
        "        target_size=self.image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_ds = test_datagen.flow_from_directory(\n",
        "        test,\n",
        "        target_size=self.image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    return train_ds , val_ds , test_ds\n",
        "\n",
        "\n",
        "\n",
        "  def build_model(self):\n",
        "\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=self.image_size + (3,)\n",
        "    )\n",
        "\n",
        "    if self.freeze_layers:\n",
        "      for layers in base_model.layers:\n",
        "        layers.trainable = False\n",
        "\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    self.model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    print(\"Model build successfully\")\n",
        "\n",
        "  def compile_model(self , learningRate):\n",
        "    self.model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"Model compiled successfully\")\n",
        "\n",
        "  def train(self , train_ds ,val_ds , epochs):\n",
        "    print(\"Training started\")\n",
        "\n",
        "    history = self.model.fit(\n",
        "        train_ds ,\n",
        "        validation_data=val_ds ,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    print(\"Training completed\")\n",
        "\n",
        "    return history\n",
        "\n",
        "  def save_model(self , path):\n",
        "    self.model.save(path)\n",
        "    print(\"Model saved successfully\")\n",
        "\n",
        "\n",
        "  def fine_tuning(self , train_ds , val_ds , unfreeze_last = 20 , learningRate=1e-5 , epochs = 10  ):\n",
        "    print(f\"Unfreezing last {unfreeze_last} layers\")\n",
        "    for layer in self.model.layers[:-unfreeze_last]:\n",
        "      if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "\n",
        "    self.compile_model(learningRate)\n",
        "\n",
        "    self.train(train_ds , val_ds , epochs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rarWn17KknRD",
        "outputId": "2c09e3e9-bcdb-4634-e926-41bcdd6d7942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5286 images belonging to 2 classes.\n",
            "Found 1511 images belonging to 2 classes.\n",
            "Found 756 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "detector = FaceMaskDetector()\n",
        "\n",
        "train_ds , val_ds , test_ds = detector.preprocessData(finalpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLlDOnhZQy0l",
        "outputId": "63b13a59-3adf-45e5-b642-5c6232e01afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Model build successfully\n"
          ]
        }
      ],
      "source": [
        "detector.build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUBrAll0XKnL",
        "outputId": "b2392ea0-e81b-41d3-da46-03dc907ec304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m159/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 2s/step - accuracy: 0.6254 - loss: 0.6655"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 2s/step - accuracy: 0.6557 - loss: 0.6306 - val_accuracy: 0.9290 - val_loss: 0.3091\n",
            "Epoch 2/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 2s/step - accuracy: 0.9043 - loss: 0.2986 - val_accuracy: 0.9651 - val_loss: 0.1802\n",
            "Epoch 3/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 2s/step - accuracy: 0.9482 - loss: 0.1941 - val_accuracy: 0.9765 - val_loss: 0.1277\n",
            "Epoch 4/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 2s/step - accuracy: 0.9624 - loss: 0.1413 - val_accuracy: 0.9805 - val_loss: 0.1028\n",
            "Epoch 5/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 2s/step - accuracy: 0.9654 - loss: 0.1287 - val_accuracy: 0.9838 - val_loss: 0.0846\n",
            "Epoch 6/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 2s/step - accuracy: 0.9701 - loss: 0.1071 - val_accuracy: 0.9849 - val_loss: 0.0751\n",
            "Epoch 7/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 2s/step - accuracy: 0.9722 - loss: 0.0943 - val_accuracy: 0.9871 - val_loss: 0.0667\n",
            "Epoch 8/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0844 - val_accuracy: 0.9875 - val_loss: 0.0598\n",
            "Epoch 9/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 2s/step - accuracy: 0.9800 - loss: 0.0776 - val_accuracy: 0.9886 - val_loss: 0.0555\n",
            "Epoch 10/10\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 2s/step - accuracy: 0.9767 - loss: 0.0761 - val_accuracy: 0.9890 - val_loss: 0.0510\n",
            "Training completed\n"
          ]
        }
      ],
      "source": [
        "history = detector.train(train_ds , val_ds , 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ont1fx8XV--",
        "outputId": "526e92a1-c57e-4b0c-e70d-88e1961673b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully\n"
          ]
        }
      ],
      "source": [
        "detector.save_model(\"best_mask_detector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNQRGkOruAwK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
